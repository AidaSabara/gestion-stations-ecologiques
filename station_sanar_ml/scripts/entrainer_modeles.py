"""
Entra√Ænement des Mod√®les de Pr√©diction ML
Station Sanar - Pr√©diction de Qualit√© d'Eau

Ce script :
1. Charge les donn√©es CSV
2. Pr√©pare les paires Entr√©e-Sortie
3. Calcule les RENDEMENTS (plus stable avec peu de donn√©es)
4. Entra√Æne des mod√®les Ridge/Lasso
5. Sauvegarde les mod√®les dans models/
6. G√©n√®re des graphiques de performance
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.linear_model import Ridge, Lasso
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
import matplotlib.pyplot as plt
import joblib
import os
import warnings
warnings.filterwarnings('ignore')

# Configuration
plt.rcParams['figure.figsize'] = (12, 8)

# ==================================================
# CLASSE PR√âPARATION DES DONN√âES
# ==================================================

class PreparateurDonnees:
    """Pr√©pare les donn√©es pour l'entra√Ænement ML"""
    
    def __init__(self, csv_path):
        self.csv_path = csv_path
        self.df = None
        
        # PAS de groupes - utiliser directement FV1, FV2, FH
        # Car dans le CSV, il n'y a pas de suffixes a, b, c
        self.groupes_filtres = {
            'FV1': ['FV1'],  # Tous les FV1 sont d√©j√† group√©s
            'FV2': ['FV2'],  # Tous les FV2 sont d√©j√† group√©s
            'FH': ['FH']     # Tous les FH sont d√©j√† group√©s
        }
    
    def charger_donnees(self):
        """Charger et nettoyer le CSV"""
        print("\nüìÇ Chargement des donn√©es...")
        self.df = pd.read_csv(self.csv_path)
        
        print(f"   Total lignes: {len(self.df)}")
        
        # Garder seulement les lignes compl√®tes (sans valeurs estim√©es)
        self.df = self.df[self.df['contient_valeurs_estimees'] == False].copy()
        
        print(f"   Lignes non estim√©es: {len(self.df)}")
        
        # Supprimer lignes avec trop de NaN
        colonnes_importantes = ['dco_mg_l', 'dbo5_mg_l', 'mes_mg_l', 'ph']
        self.df = self.df.dropna(subset=colonnes_importantes, thresh=3)
        
        print(f"‚úÖ Donn√©es nettoy√©es: {len(self.df)} lignes")
        
        return self
    
    def creer_paires_entree_sortie(self, groupe_filtre):
        """
        Cr√©er des paires (Entr√©e, Sortie) pour un groupe de filtres
        
        Strat√©gie: Regrouper les filtres similaires (a, b, c) pour avoir plus de donn√©es
        """
        
        print(f"\nüîÑ Cr√©ation des paires pour {groupe_filtre}...")
        
        # D√©terminer le filtre d'entr√©e associ√©
        if groupe_filtre == 'FH':
            id_filtre_entree = 'General'
        else:
            id_filtre_entree = groupe_filtre  # FV1 ou FV2
        
        # Extraire les entr√©es
        entrees = self.df[
            (self.df['phase'] == 'Entree') & 
            (self.df['id_filtre'] == id_filtre_entree)
        ].copy()
        
        # Extraire les sorties
        filtres_sortie = self.groupes_filtres[groupe_filtre]
        sorties = self.df[
            (self.df['phase'] == 'Sortie') & 
            (self.df['id_filtre'].isin(filtres_sortie))
        ].copy()
        
        print(f"   Entr√©es: {len(entrees)}")
        print(f"   Sorties: {len(sorties)}")
        
        if len(entrees) == 0 or len(sorties) == 0:
            print(f"‚ö†Ô∏è  Pas assez de donn√©es pour {groupe_filtre}")
            return None
        
        # Simplifier: prendre la moyenne des sorties (si plusieurs a, b, c par lot)
        # Pour simplifier, on associe par ordre (assumer ordre chronologique)
        
        min_len = min(len(entrees), len(sorties))
        
        if min_len < 3:
            print(f"‚ö†Ô∏è  Seulement {min_len} paires - trop peu pour ML fiable")
            return None
        
        # Cr√©er le dataset pair√©
        paires = pd.DataFrame()
        
        # Features d'entr√©e (X)
        paires['entree_dco'] = entrees['dco_mg_l'].iloc[:min_len].values
        paires['entree_dbo5'] = entrees['dbo5_mg_l'].iloc[:min_len].values
        paires['entree_mes'] = entrees['mes_mg_l'].iloc[:min_len].values
        paires['entree_ph'] = entrees['ph'].iloc[:min_len].values
        paires['entree_ammonium'] = entrees['ammonium_mg_l'].iloc[:min_len].values
        
        # Sorties (y)
        paires['sortie_dco'] = sorties['dco_mg_l'].iloc[:min_len].values
        paires['sortie_dbo5'] = sorties['dbo5_mg_l'].iloc[:min_len].values
        paires['sortie_mes'] = sorties['mes_mg_l'].iloc[:min_len].values
        
        print(f"‚úÖ {len(paires)} paires cr√©√©es")
        
        return paires
    
    def calculer_rendements(self, paires):
        """
        Calculer les RENDEMENTS au lieu des valeurs absolues
        
        Pourquoi ? Plus stable avec peu de donn√©es !
        Rendement = (Entr√©e - Sortie) / Entr√©e √ó 100
        """
        
        if paires is None:
            return None
        
        rendements = pd.DataFrame()
        
        # Calculer rendements en pourcentage
        rendements['rendement_dco'] = (
            (paires['entree_dco'] - paires['sortie_dco']) / paires['entree_dco'] * 100
        )
        rendements['rendement_dbo5'] = (
            (paires['entree_dbo5'] - paires['sortie_dbo5']) / paires['entree_dbo5'] * 100
        )
        rendements['rendement_mes'] = (
            (paires['entree_mes'] - paires['sortie_mes']) / paires['entree_mes'] * 100
        )
        
        # Garder les features d'entr√©e
        rendements['entree_dco'] = paires['entree_dco']
        rendements['entree_dbo5'] = paires['entree_dbo5']
        rendements['entree_mes'] = paires['entree_mes']
        rendements['entree_ph'] = paires['entree_ph']
        rendements['entree_ammonium'] = paires['entree_ammonium']
        
        # NETTOYAGE PLUS STRICT des valeurs aberrantes
        print(f"   Avant nettoyage: {len(rendements)} √©chantillons")
        
        for col in ['rendement_dco', 'rendement_dbo5', 'rendement_mes']:
            # Supprimer rendements impossibles
            rendements = rendements[
                (rendements[col] >= -10) & (rendements[col] <= 100)  # Tol√©rer -10% pour erreurs mesure
            ]
        
        # Supprimer lignes avec valeurs d'entr√©e aberrantes (< 10 ou > 5000)
        for col in ['entree_dco', 'entree_dbo5']:
            rendements = rendements[
                (rendements[col] >= 10) & (rendements[col] <= 5000)
            ]
        
        print(f"   Apr√®s nettoyage: {len(rendements)} √©chantillons valides")
        
        if len(rendements) < 3:
            print(f"   ‚ö†Ô∏è  Pas assez de donn√©es apr√®s nettoyage")
            return None
        
        return rendements

    def engineer_features(self, rendements):
        """
        Feature Engineering 
        """
        if rendements is None:
            return None
        
        df = rendements.copy()
        
        # 1. Ratio DCO/DBO5 seulement
        df['ratio_dco_dbo5'] = df['entree_dco'] / df['entree_dbo5']
        
        
        # G√©rer les valeurs infinies cr√©√©es par les divisions
        df = df.replace([np.inf, -np.inf], np.nan)
        df = df.dropna()
        
        print(f"   Feature engineering: {len(df.columns)} variables cr√©√©es")
        
        return df


# ==================================================
# CLASSE MOD√àLE ML
# ==================================================

class ModeleRendement:
    """Mod√®le de pr√©diction des rendements"""
    
    def __init__(self, alpha=1.0, use_lasso=False):
        self.model = Lasso(alpha=alpha, max_iter=5000) if use_lasso else Ridge(alpha=alpha)
        self.scaler = StandardScaler()
        self.features = None
        self.target = None
        self.metrics = {}
    
    def preparer_features(self, rendements, target, features):
        """Pr√©parer X et y"""
        
        X = rendements[features].copy()
        y = rendements[target].copy()
        
        # Supprimer les NaN
        mask = ~(X.isna().any(axis=1) | y.isna())
        X = X[mask]
        y = y[mask]
        
        self.features = features
        self.target = target
        
        return X, y
    
    def entrainer(self, X, y, test_size=0.2):
        """Entra√Æner le mod√®le avec validation"""
        
        if len(X) < 5:
            print(f"‚ö†Ô∏è  ATTENTION: Seulement {len(X)} √©chantillons - Risque d'overfitting!")
        
        # Split train/test
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=test_size, random_state=42, shuffle=True
        )
        
        # Normalisation
        X_train_scaled = self.scaler.fit_transform(X_train)
        X_test_scaled = self.scaler.transform(X_test)
        
        # Entra√Ænement
        self.model.fit(X_train_scaled, y_train)
        
        # Pr√©dictions
        y_pred_train = self.model.predict(X_train_scaled)
        y_pred_test = self.model.predict(X_test_scaled)
        
        # Validation crois√©e K=3 comme d√©crit dans le chapitre 2.5.4.3
        cv_folds = min(3, len(X_train))  # K=3 folds, adapt√© √† la taille des donn√©es
        cv_scores = cross_val_score(
            self.model, X_train_scaled, y_train, 
            cv=cv_folds, 
            scoring='r2'
        )
        
        # M√©triques COMPL√àTES avec validation crois√©e
        self.metrics = {
            'train_r2': r2_score(y_train, y_pred_train),
            'test_r2': r2_score(y_test, y_pred_test),
            'train_rmse': np.sqrt(mean_squared_error(y_train, y_pred_train)),
            'test_rmse': np.sqrt(mean_squared_error(y_test, y_pred_test)),
            'train_mae': mean_absolute_error(y_train, y_pred_train),
            'test_mae': mean_absolute_error(y_test, y_pred_test),
            'cv_r2_mean': cv_scores.mean(),           # NOUVEAU
            'cv_r2_std': cv_scores.std(),             # NOUVEAU
            'cv_folds': cv_folds,                     # NOUVEAU
            'n_samples': len(X),
            'n_features': len(self.features)
        }
        
        return self.metrics, (X_test, y_test, y_pred_test)
    
    def predire(self, X_new):
        """Pr√©dire le rendement pour nouvelles donn√©es"""
        X_scaled = self.scaler.transform(X_new)
        return self.model.predict(X_scaled)
    
    def sauvegarder(self, filepath):
        """Sauvegarder le mod√®le"""
        os.makedirs(os.path.dirname(filepath), exist_ok=True)
        
        joblib.dump({
            'model': self.model,
            'scaler': self.scaler,
            'features': self.features,
            'target': self.target,
            'metrics': self.metrics
        }, filepath)
        
        print(f"‚úÖ Mod√®le sauvegard√©: {filepath}")
    
    @classmethod
    def charger(cls, filepath):
        """Charger un mod√®le sauvegard√©"""
        data = joblib.load(filepath)
        
        modele = cls()
        modele.model = data['model']
        modele.scaler = data['scaler']
        modele.features = data['features']
        modele.target = data['target']
        modele.metrics = data.get('metrics', {})
        
        return modele


# ==================================================
# FONCTIONS DE VISUALISATION
# ==================================================

def afficher_metriques(metrics, nom_modele):
    """Afficher les m√©triques de performance"""
    
    print(f"\nüìä M√©triques - {nom_modele}")
    print("-" * 60)
    print(f"  R¬≤ Train:        {metrics['train_r2']:.3f}")
    print(f"  R¬≤ Test:         {metrics['test_r2']:.3f}")
    print(f"  R¬≤ CV (K={metrics['cv_folds']}): {metrics['cv_r2_mean']:.3f} ¬± {metrics['cv_r2_std']:.3f}")
    print(f"  RMSE Train:      {metrics['train_rmse']:.2f}%")
    print(f"  RMSE Test:       {metrics['test_rmse']:.2f}%")
    print(f"  √âchantillons:    {metrics['n_samples']}")
    print(f"  Features:        {metrics['n_features']}")
    
    # Diagnostic am√©lior√©
    ecart_train_test = abs(metrics['train_r2'] - metrics['test_r2'])
    ecart_cv_test = abs(metrics['cv_r2_mean'] - metrics['test_r2'])
    
    if ecart_train_test > 0.2:
        print(f"\n  ‚ö†Ô∏è  √âcart Train-Test √©lev√© ({ecart_train_test:.3f}) ‚Üí Risque d'overfitting")
    elif metrics['test_r2'] < 0.5:
        print(f"\n  ‚ö†Ô∏è  R¬≤ Test faible ({metrics['test_r2']:.3f}) ‚Üí Mod√®le peu pr√©cis")
    elif ecart_cv_test > 0.15:
        print(f"\n  ‚ö†Ô∏è  √âcart CV-Test ({ecart_cv_test:.3f}) ‚Üí Validation crois√©e √† consid√©rer")
    else:
        print(f"\n  ‚úÖ Mod√®le robuste et fiable")


def creer_graphiques(y_test, y_pred, nom_modele, output_dir='../graphiques'):
    """Cr√©er graphiques de performance"""
    
    os.makedirs(output_dir, exist_ok=True)
    
    fig, axes = plt.subplots(1, 2, figsize=(14, 5))
    
    # Scatter plot: Pr√©dit vs R√©el
    axes[0].scatter(y_test, y_pred, alpha=0.6, s=100, edgecolors='black')
    axes[0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 
                 'r--', lw=2, label='Pr√©diction parfaite')
    axes[0].set_xlabel('Rendement R√©el (%)', fontsize=12)
    axes[0].set_ylabel('Rendement Pr√©dit (%)', fontsize=12)
    axes[0].set_title(f'Pr√©dictions vs R√©el - {nom_modele}', fontsize=14, fontweight='bold')
    axes[0].legend()
    axes[0].grid(alpha=0.3)
    
    # R√©sidus
    residus = y_test.values - y_pred
    axes[1].scatter(y_pred, residus, alpha=0.6, s=100, edgecolors='black', color='coral')
    axes[1].axhline(y=0, color='r', linestyle='--', lw=2)
    axes[1].set_xlabel('Rendement Pr√©dit (%)', fontsize=12)
    axes[1].set_ylabel('R√©sidus (%)', fontsize=12)
    axes[1].set_title('Analyse des R√©sidus', fontsize=14, fontweight='bold')
    axes[1].grid(alpha=0.3)
    
    plt.tight_layout()
    
    filepath = os.path.join(output_dir, f'{nom_modele}_performance.png')
    plt.savefig(filepath, dpi=300, bbox_inches='tight')
    print(f"üìä Graphique sauvegard√©: {filepath}")
    plt.close()


# ==================================================
# FONCTION PRINCIPALE
# ==================================================

def main():
    """Entra√Æner tous les mod√®les"""
    
    print("\n" + "="*70)
    print("  ü§ñ ENTRA√éNEMENT DES MOD√àLES ML - STATION SANAR")
    print("  Pr√©diction des Rendements d'√âpuration")
    print("="*70)
    
    # Chemin du CSV
    csv_path = '../data/UGB_Sanar_Station_Final.csv'
    
    if not os.path.exists(csv_path):
        print(f"\n‚ùå Fichier introuvable: {csv_path}")
        print("\nüí° Solution: Placez votre CSV dans le dossier data/")
        return
    
    # Pr√©paration des donn√©es
    prep = PreparateurDonnees(csv_path)
    prep.charger_donnees()
    
    # Configuration SIMPLIFI√âE - Moins de features
    configurations = [
        # (groupe_filtre, variable_cible, features)
        ('FV1', 'rendement_dco', ['entree_dco', 'entree_ph', 'entree_mes']),
        ('FV1', 'rendement_dbo5', ['entree_dbo5', 'entree_ph', 'entree_mes']),
        ('FV2', 'rendement_dco', ['entree_dco', 'entree_ph']),
        ('FV2', 'rendement_dbo5', ['entree_dbo5', 'entree_ph']),
        ('FH', 'rendement_dco', ['entree_dco', 'entree_ph', 'entree_mes']),
        ('FH', 'rendement_dbo5', ['entree_dbo5', 'entree_ph', 'entree_mes']),
    ]
    
    modeles_entraines = []
    tous_metrics = []
    
    for groupe, target, features in configurations:
        print("\n" + "="*70)
        print(f"  ENTRA√éNEMENT: {groupe} - {target}")
        print("="*70)
        
        # Pr√©parer donn√©es
        paires = prep.creer_paires_entree_sortie(groupe)
        if paires is None:
            continue
        
        rendements = prep.calculer_rendements(paires)
        if rendements is None or len(rendements) < 3:
            print(f"‚ö†Ô∏è  Pas assez de donn√©es pour {groupe}")
            continue
        
        # AJOUT: Feature Engineering
        rendements = prep.engineer_features(rendements)
        if rendements is None or len(rendements) < 3:
            print(f"‚ö†Ô∏è  Donn√©es insuffisantes apr√®s feature engineering")
            continue
        
        # Cr√©er et entra√Æner mod√®le
        modele = ModeleRendement(alpha=0.5)
        
        try:
            X, y = modele.preparer_features(rendements, target, features)
            
            if len(X) < 3:
                print(f"‚ö†Ô∏è  Seulement {len(X)} √©chantillons - skipp√©")
                continue
            
            metrics, (X_test, y_test, y_pred) = modele.entrainer(X, y)
            
            # Afficher r√©sultats
            nom_modele = f"{groupe}_{target.split('_')[1]}"
            afficher_metriques(metrics, nom_modele)
            
            # Sauvegarder mod√®le
            modele.sauvegarder(f'../models/{nom_modele}_model.pkl')
            
            # Cr√©er graphiques
            if len(X_test) > 0:
                creer_graphiques(y_test, y_pred, nom_modele)
            
            modeles_entraines.append(nom_modele)
            tous_metrics.append((nom_modele, metrics))
            
        except Exception as e:
            print(f"‚ùå Erreur: {e}")
            continue
    
    # R√©sum√© final
    print("\n" + "="*70)
    print("  ‚úÖ ENTRA√éNEMENT TERMIN√â")
    print("="*70)
    print(f"\nMod√®les cr√©√©s: {len(modeles_entraines)}")
    for nom in modeles_entraines:
        print(f"  ‚úì {nom}")
    
    print(f"\nFichiers sauvegard√©s dans:")
    print(f"  - Mod√®les: models/")
    print(f"  - Graphiques: graphiques/")
    
    if tous_metrics:
        print(f"\nüìä Performance moyenne:")
        r2_moyen = np.mean([m[1]['test_r2'] for m in tous_metrics])
        print(f"  R¬≤ Test moyen: {r2_moyen:.3f}")
        
        if r2_moyen < 0.6:
            print(f"\nüí° Conseils d'am√©lioration:")
            print(f"  ‚Ä¢ Collecter plus de donn√©es (actuellement ~{prep.df.shape[0]} lignes)")
            print(f"  ‚Ä¢ Ajouter des variables (temp√©rature, d√©bit...)")
            print(f"  ‚Ä¢ R√©entra√Æner dans 3-6 mois avec nouvelles donn√©es")


if __name__ == "__main__":
    main()